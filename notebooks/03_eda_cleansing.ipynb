{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a href=\"#define functions\">define functions</a>\n",
    "2. <a href=\"#Define paths and capture data\">Define paths and capture data</a>\n",
    "3. <a href=\"#missing data\">missing data</a>\n",
    "4. <a href=\"#anomaly detection\">anomaly detection</a>\n",
    "5. <a href=\"#Visualize pairwise relations\">Visualize pairwise relations</a>\n",
    "6. <a href=\"#Check if data is imbalanced\">Check if data is imbalanced</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "from impyute.imputation.cs import fast_knn\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "# %matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set sandbox_mode boolean for image building\n",
    "* if sandbox_mode = True: faster to run, but images won't be generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandbox_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"define functions\">define functions</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_mask(df):\n",
    "    type_mask = []\n",
    "    for i in df.dtypes:\n",
    "        if str(i).startswith('float') or str(i).startswith('int'): # or str(i).startswith('bool')\n",
    "            type_mask.append(True)\n",
    "        else: type_mask.append(False)\n",
    "    num_cols = list(np.array(df.columns)[type_mask])\n",
    "    other_cols = list(np.array(df.columns)[[not elem for elem in type_mask]])\n",
    "    \n",
    "    return num_cols, other_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions related to missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing(df):\n",
    "    total = df.isnull().sum()\n",
    "    percent = (df.isnull().sum()/df.isnull().count())\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['total', 'percent_missing'])\n",
    "    missing_data['percent_missing'] = missing_data['percent_missing']\n",
    "    missing_data['percent_missing'] = missing_data['percent_missing'].apply(lambda x: round(x,2))\n",
    "    \n",
    "    return missing_data\n",
    "\n",
    "def drop_missing_from_threshold(df, row_threshold, col_threshold):\n",
    "    row_count, col_count = df.shape\n",
    "    # drop columns according to threshold of missing; use mask of columns which have less missing than threshold\n",
    "    df = df.iloc[:, (df_missing['percent_missing'] < col_threshold).to_list()]\n",
    "    \n",
    "    # drop row according to threshold of missing\n",
    "    n_cols = df.shape[1]\n",
    "    df['ratio_mis'] = df.apply(lambda x: (n_cols - x.count())/n_cols, axis=1)\n",
    "    df = df[df['ratio_mis']<row_threshold]\n",
    "    df.drop(['ratio_mis'], axis=1, inplace=True)\n",
    "    \n",
    "    # count number of removals\n",
    "    row_count_new, col_count_new = df.shape\n",
    "    row_count_removal = row_count - row_count_new\n",
    "    col_count_removal = col_count - col_count_new\n",
    "    print('{} rows and {} columns were removed from database'.format(row_count_removal, col_count_removal))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def apply_imputation(df, method = 'knn', k=30, manual_val=-1):\n",
    "    try:\n",
    "        assert method in ['knn', 'mode', 'median', -1, 'manual']\n",
    "    except AssertionError:\n",
    "        raise ValueError('error: select a correct method for imputation: [knn, mode, median, -1, manual]')\n",
    "        \n",
    "    if method == 'knn':\n",
    "        sys.setrecursionlimit(100000) #Increase the recursion limit of the OS\n",
    "        numerical_cols, other_cols = get_numerical_mask(df)\n",
    "        \n",
    "#         df =  StandardScaler().fit_transform(df) # scale for knn to work properly (it's distance based)\n",
    "\n",
    "        # start the KNN training\n",
    "        imputed_training = fast_knn(df[numerical_cols], k=30)\n",
    "\n",
    "        # retrieve column names\n",
    "        imp_cols = imputed_training.columns.to_list()\n",
    "        imputed_training.rename({imp_cols[i]: numerical_cols[i] for i in range(len(imp_cols))}, axis = 1, inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        other_cols.append('id')\n",
    "        df = df[other_cols].merge(imputed_training, left_index=True, right_index=True)\n",
    "        df.set_index('id', inplace=True)\n",
    "        \n",
    "    elif method == 'mode':\n",
    "        df.fillna(data.mode().iloc[0], inplace=True)\n",
    "        \n",
    "    elif method == 'median':\n",
    "        df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    elif method == -1:\n",
    "        df.fillna(-1, inplace=True)\n",
    "    \n",
    "    elif method == 'manual':\n",
    "        df.fillna(manual_val, inplace=True)\n",
    "        \n",
    "    try:\n",
    "        assert df[df.isna().any(axis=1)].shape[0] == 0\n",
    "    except AssertionError:\n",
    "        raise ValueError('there are still missing values')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions related to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_standard_deviation_tol(df, tol=3):\n",
    "    #scale data for operation\n",
    "    df = pd.DataFrame(StandardScaler().fit_transform(df[numerical_cols]))\n",
    "    \n",
    "    z = np.abs(stats.zscore(df))\n",
    "    z = pd.DataFrame(z, columns = df.columns, index=df.index)\n",
    "    z.fillna(0, inplace=True)\n",
    "    for col in z.columns[2:]:\n",
    "        z = z[z[col]<tol]\n",
    "    print(\"{0:.2%} of data was removed after dealing with outliers\".format((df.shape[0]-z.shape[0])/df.shape[0]))\n",
    "    df = df.loc[z.index, :]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def apply_isolation_forest(df, contamination=0.05):\n",
    "    clf = IsolationForest(max_samples='auto', contamination=contamination, random_state=42) # contamination='auto' or 0.05\n",
    "    clf.fit(df)\n",
    "\n",
    "    outlier_pred = clf.predict(df)\n",
    "    print('number of outliers:', np.count_nonzero(outlier_pred == -1), 'from a total of {}'.format(len(outlier_pred)))\n",
    "    print('percentage of outliers: {0:.0%}'.format(np.count_nonzero(outlier_pred == -1)/np.count_nonzero(outlier_pred == 1)))\n",
    "    \n",
    "    return outlier_pred\n",
    "\n",
    "def get_outliers(df, label, cols, method = 'isolation_forest', if_contamination = 0.05, z_tol = 3):\n",
    "\n",
    "    if method == 'isolation_forest':\n",
    "        outliers = apply_isolation_forest(df, if_contamination)\n",
    "    elif method == 'standard_deviation_tol':\n",
    "        df = apply_standard_deviation_tol(df, z_tol)\n",
    "    \n",
    "    print(len(outliers))\n",
    "    return outliers, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"Define paths and capture data\">Define paths and capture data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = os.path.join('..', 'data', '02_intermediate')\n",
    "outputs = os.path.join('..', 'data', '02_intermediate')\n",
    "reports = os.path.join('..', 'data', '06_reporting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data               = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "data_test          = pd.read_csv(os.path.join(inputs, 'X_test.csv'), index_col='id')\n",
    "y_train            = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id')\n",
    "y_test             = pd.read_csv(os.path.join(inputs, 'y_test.csv'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions: (354, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "id                                                                       \n",
       "0   0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1   0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2   0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3   0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4   0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "    ptratio       b  lstat  \n",
       "id                          \n",
       "0      15.3  396.90   4.98  \n",
       "1      17.8  396.90   9.14  \n",
       "2      17.8  392.83   4.03  \n",
       "3      18.7  394.63   2.94  \n",
       "4      18.7  396.90   5.33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataset dimensions:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking  for possible anomalies in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>354.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.398733</td>\n",
       "      <td>15.790960</td>\n",
       "      <td>8.379435</td>\n",
       "      <td>0.076271</td>\n",
       "      <td>0.509889</td>\n",
       "      <td>6.403842</td>\n",
       "      <td>60.558192</td>\n",
       "      <td>4.478163</td>\n",
       "      <td>4.471751</td>\n",
       "      <td>310.564972</td>\n",
       "      <td>17.709040</td>\n",
       "      <td>380.506412</td>\n",
       "      <td>10.369718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.639774</td>\n",
       "      <td>26.017946</td>\n",
       "      <td>6.093557</td>\n",
       "      <td>0.265807</td>\n",
       "      <td>0.102235</td>\n",
       "      <td>0.674397</td>\n",
       "      <td>28.422028</td>\n",
       "      <td>2.057119</td>\n",
       "      <td>1.609301</td>\n",
       "      <td>68.032258</td>\n",
       "      <td>2.189669</td>\n",
       "      <td>40.292422</td>\n",
       "      <td>5.879347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>4.903000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.321600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>70.800000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.057822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.970000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>5.949250</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>2.777800</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>383.640000</td>\n",
       "      <td>6.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.131375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>6.269500</td>\n",
       "      <td>61.650000</td>\n",
       "      <td>4.120500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>392.580000</td>\n",
       "      <td>9.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.398352</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>6.727750</td>\n",
       "      <td>88.350000</td>\n",
       "      <td>5.934125</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>396.192500</td>\n",
       "      <td>13.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.097400</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>21.200000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>34.410000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             crim          zn       indus        chas         nox          rm  \\\n",
       "count  354.000000  354.000000  354.000000  354.000000  354.000000  354.000000   \n",
       "mean     0.398733   15.790960    8.379435    0.076271    0.509889    6.403842   \n",
       "std      0.639774   26.017946    6.093557    0.265807    0.102235    0.674397   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    4.903000   \n",
       "25%      0.057822    0.000000    3.970000    0.000000    0.437000    5.949250   \n",
       "50%      0.131375    0.000000    6.200000    0.000000    0.489000    6.269500   \n",
       "75%      0.398352   22.000000   10.010000    0.000000    0.542500    6.727750   \n",
       "max      4.097400  100.000000   25.650000    1.000000    0.871000    8.725000   \n",
       "\n",
       "              age         dis         rad         tax     ptratio           b  \\\n",
       "count  354.000000  354.000000  354.000000  354.000000  354.000000  354.000000   \n",
       "mean    60.558192    4.478163    4.471751  310.564972   17.709040  380.506412   \n",
       "std     28.422028    2.057119    1.609301   68.032258    2.189669   40.292422   \n",
       "min      2.900000    1.321600    1.000000  187.000000   12.600000   70.800000   \n",
       "25%     35.750000    2.777800    4.000000  264.000000   16.100000  383.640000   \n",
       "50%     61.650000    4.120500    4.000000  304.000000   17.900000  392.580000   \n",
       "75%     88.350000    5.934125    5.000000  358.000000   19.100000  396.192500   \n",
       "max    100.000000   12.126500    8.000000  469.000000   21.200000  396.900000   \n",
       "\n",
       "            lstat  \n",
       "count  354.000000  \n",
       "mean    10.369718  \n",
       "std      5.879347  \n",
       "min      1.730000  \n",
       "25%      6.055000  \n",
       "50%      9.285000  \n",
       "75%     13.150000  \n",
       "max     34.410000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"missing data\">missing data</a>\n",
    "\n",
    "usually, missing data is solved by filling it with some metric such as median. If the number of missing data in some entry is too high, we must evaluate for the removal of those entries.\n",
    "For categorical with missing data, if you want to encode missing values, first change its type to a string:\n",
    "```python\n",
    "a[pd.isnull(a)]  = 'NaN'\n",
    "```\n",
    "Some refs:\n",
    "* https://stackoverflow.com/questions/36808434/label-encoder-encoding-missing-values\n",
    "\n",
    "About the missing values, we can't assume beforehand if those are Missing at Random (MAR) or Missing not at Random (MNAR). Further investigation would be necessary to properly decide over how to handle it.\n",
    "\n",
    "For now, I am assuming they are Missing at Random. So I will remove some of them through a threshold, and apply imputation for the rest. By applying a proper imputation I observed a slight improvement over the score.\n",
    "\n",
    "The catch is that applying imputation over euclidean distances can be extremely imprecise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop columns and rows for threshold of missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SORTED LIST OF MISSING VALUES\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total</th>\n",
       "      <th>percent_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [total, percent_missing]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('SORTED LIST OF MISSING VALUES')\n",
    "df_missing = get_missing(data)\n",
    "df_missing_vis = df_missing[df_missing['total'] > 0]\n",
    "df_missing_vis['percent_missing'] = df_missing_vis['percent_missing'].apply(lambda x: round(x, 2))\n",
    "# df_missing_vis.sort_values(by='percent_missing', ascending=False).head(20)\n",
    "df_missing_vis.sort_values(by='percent_missing', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_mis_threshold = 0.8\n",
    "row_mis_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows and 0 columns were removed from database\n"
     ]
    }
   ],
   "source": [
    "data = drop_missing_from_threshold(data, row_mis_threshold, col_mis_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize rows with missing\n",
    "we already know that the critical columns are related to geo_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, b, lstat]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandbox_mode = True\n",
    "if sandbox_mode:\n",
    "    print('number of missing:', data[data.isna().any(axis=1)].shape[0])\n",
    "data[data.isna().any(axis=1)].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get types of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols, other_cols = get_numerical_mask(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputation of missing values\n",
    "For continuous values, I would prefer knn over median, but it depends on normalized dataset. Nevertheless, we don't have missing on continuous datasets, even though we could encode categorical data. But the encoding step wasn't organized to precede this notebook, so I will stick to 'mode', which imputes the most frequent value.\n",
    "\n",
    "Some refs:\n",
    "* https://jamesrledoux.com/code/imputation#:~:text=One%20approach%20to%20imputing%20categorical,given%20in%20Pandas'%20value_counts%20function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the apply_imputation function accepts the following methods: knn, median, mode, or -1 (impute as category -1 [for categorical vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation over numerical variables\n",
    "data[numerical_cols] = data[numerical_cols].astype(float)\n",
    "if data[numerical_cols].isnull().values.any():\n",
    "    data[numerical_cols] = apply_imputation(data[numerical_cols], method = 'knn', k = 30)\n",
    "\n",
    "# imputation over categorical variables\n",
    "# if data[other_cols].isnull().values.any():\n",
    "data[other_cols] = apply_imputation(data[other_cols], method = 'mode', k = 30)\n",
    "\n",
    "# manual imputation on lag and forecast variables\n",
    "# manual_cols = ['lag_1', 'lag_2', 'lag_3']\n",
    "# if data[manual_cols].isnull().values.any():\n",
    "#     data[manual_cols] = apply_imputation(data[manual_cols], method = 'manual', manual_val = False)\n",
    "# data_test['y'].fillna(value=data_test['y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation over numerical variables\n",
    "data_test[numerical_cols] = data_test[numerical_cols].astype(float)\n",
    "if data_test[numerical_cols].isnull().values.any():\n",
    "    data_test[numerical_cols] = apply_imputation(data_test[numerical_cols], method = 'knn', k = 30)\n",
    "\n",
    "# imputation over categorical variables\n",
    "if data_test[other_cols].isnull().values.any():\n",
    "    data_test[other_cols] = apply_imputation(data_test[other_cols], method = 'mode', k = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"anomaly detection\">anomaly detection</a>\n",
    "\n",
    "remove outliers from choosing one of the following methods: isolation_forest, standard_deviation_tol (using z_score on standardized version)\n",
    "\n",
    "other parameters are:\n",
    "* if_contamination: isolation forest level of contamination\n",
    "* z_tol: tolerance for standard deviation (if using zscore)\n",
    "\n",
    "It is not advisable to remove outliers without proper consideration.\n",
    "\n",
    "Some interesting refs:\n",
    "* https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "* https://towardsdatascience.com/anomaly-detection-with-isolation-forest-visualization-23cd75c281e2\n",
    "* https://towardsdatascience.com/outlier-detection-with-isolation-forest-3d190448d45e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of outliers: 18 from a total of 354\n",
      "percentage of outliers: 5%\n",
      "354\n",
      "number of outliers: 26 from a total of 506\n",
      "percentage of outliers: 5%\n",
      "506\n"
     ]
    }
   ],
   "source": [
    "# temporarily add train to test data (no leakage here)\n",
    "test_start = data_test.index[0]\n",
    "data_test = data.append(data_test)\n",
    "\n",
    "# get outliers on train data\n",
    "data['if_anomaly'], _ = get_outliers(data[numerical_cols], y_train, numerical_cols, \n",
    "                                                  method = 'isolation_forest', if_contamination = 0.05)\n",
    "\n",
    "# get outliers on test data (needs trainset)\n",
    "\n",
    "data_test['if_anomaly'], _ = get_outliers(data_test[numerical_cols], y_train, numerical_cols, \n",
    "                                                  method = 'isolation_forest', if_contamination = 0.05)\n",
    "\n",
    "# removes trainset again\n",
    "data_test = data_test.iloc[len(data):,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outlier removal isn't justified for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_outliers = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_outliers:\n",
    "    data = data[data['if_anomaly'] == 1]\n",
    "    y_train = y_train[y_train.index.isin(data.index.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>if_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.04301</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.663</td>\n",
       "      <td>21.9</td>\n",
       "      <td>10.5857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>382.80</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.10659</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.936</td>\n",
       "      <td>19.5</td>\n",
       "      <td>10.5857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>376.04</td>\n",
       "      <td>5.57</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>8.98296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770</td>\n",
       "      <td>6.212</td>\n",
       "      <td>97.4</td>\n",
       "      <td>2.1222</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>377.73</td>\n",
       "      <td>17.60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3.84970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770</td>\n",
       "      <td>6.395</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.5052</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.34</td>\n",
       "      <td>13.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>5.20177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770</td>\n",
       "      <td>6.127</td>\n",
       "      <td>83.4</td>\n",
       "      <td>2.7227</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.43</td>\n",
       "      <td>11.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age      dis   rad    tax  \\\n",
       "id                                                                          \n",
       "354  0.04301  80.0   1.91   0.0  0.413  5.663  21.9  10.5857   4.0  334.0   \n",
       "355  0.10659  80.0   1.91   0.0  0.413  5.936  19.5  10.5857   4.0  334.0   \n",
       "356  8.98296   0.0  18.10   1.0  0.770  6.212  97.4   2.1222  24.0  666.0   \n",
       "357  3.84970   0.0  18.10   1.0  0.770  6.395  91.0   2.5052  24.0  666.0   \n",
       "358  5.20177   0.0  18.10   1.0  0.770  6.127  83.4   2.7227  24.0  666.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...      ...   ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1   2.4786   1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7   2.2875   1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0   2.1675   1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3   2.3889   1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8   2.5050   1.0  273.0   \n",
       "\n",
       "     ptratio       b  lstat  if_anomaly  \n",
       "id                                       \n",
       "354     22.0  382.80   8.05           1  \n",
       "355     22.0  376.04   5.57          -1  \n",
       "356     20.2  377.73  17.60           1  \n",
       "357     20.2  391.34  13.27           1  \n",
       "358     20.2  395.43  11.48           1  \n",
       "..       ...     ...    ...         ...  \n",
       "501     21.0  391.99   9.67           1  \n",
       "502     21.0  396.90   9.08           1  \n",
       "503     21.0  396.90   5.64           1  \n",
       "504     21.0  393.45   6.48           1  \n",
       "505     21.0  396.90   7.88           1  \n",
       "\n",
       "[152 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop redundant features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.drop(['if_anomaly'], axis=1, inplace=True)\n",
    "data_test.drop(['if_anomaly'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build new variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id=\"Visualize pairwise relations\">Visualize pairwise relations</a>\n",
    "When datasets have just a few variables (10–15), pairplots allow for a quick visual inspection of those relations, as well as bariable distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols, other_cols = get_numerical_mask(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = int(len(numerical_cols)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sandbox_mode:\n",
    "    data_vis = data[numerical_cols[:separator]]\n",
    "    data_vis['y'] = y_train['y']\n",
    "    print('visualize pairplots')\n",
    "    sns.pairplot(data_vis, plot_kws={'alpha': 0.1});\n",
    "    plt.savefig(os.path.join(reports,'01_pairplots_1.jpg'), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sandbox_mode:\n",
    "    data_vis = data[numerical_cols[separator:]]\n",
    "    data_vis['y'] = y_train['y']\n",
    "    print('visualize pairplots')\n",
    "    sns.pairplot(data_vis, plot_kws={'alpha': 0.1});\n",
    "    plt.savefig(os.path.join(reports,'01_pairplots_2.jpg'), bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description (2nd round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "354\n",
      "152\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "if sandbox_mode:\n",
    "    print(data.shape[0])\n",
    "    print(y_train.shape[0])\n",
    "    print(data_test.shape[0])\n",
    "    print(y_test.shape[0])\n",
    "    data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(os.path.join(outputs, 'X_train.csv'))\n",
    "data_test.to_csv(os.path.join(outputs, 'X_test.csv'))\n",
    "\n",
    "y_train.to_csv(os.path.join(outputs, 'y_train.csv'))\n",
    "y_test.to_csv(os.path.join(outputs, 'y_test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
