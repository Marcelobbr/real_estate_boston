{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer as Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join('..', 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import model\n",
    "importlib.reload(model)\n",
    "\n",
    "from model import get_model_params, timer, measure_prediction_time, apply_ml_model, save_model_parameters, save_model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set model parameters and capture data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 14)\n",
      "(354, 14)\n",
      "(354, 1)\n"
     ]
    }
   ],
   "source": [
    "inputs = os.path.join('..', 'data', '03_processed')\n",
    "models_reports = os.path.join('..', 'data', '04_models')\n",
    "model_outputs = os.path.join('..', 'data', '05_model_output')\n",
    "reports = os.path.join('..', 'data', '06_reporting')\n",
    "\n",
    "X_train            = pd.read_csv(os.path.join(inputs, 'X_train.csv'), index_col='id')\n",
    "X_train_onehot         = pd.read_csv(os.path.join(inputs, 'X_train_onehot.csv'), index_col='id')\n",
    "y_train            = pd.read_csv(os.path.join(inputs, 'y_train.csv'), index_col='id')\n",
    "\n",
    "data_list = [X_train, X_train_onehot, y_train]\n",
    "\n",
    "for df in data_list:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>if_anomaly</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad    tax  \\\n",
       "id                                                                       \n",
       "0   0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1   0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2   0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3   0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4   0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "    ptratio       b  lstat  if_anomaly  \n",
       "id                                      \n",
       "0      15.3  396.90   4.98           1  \n",
       "1      17.8  396.90   9.14           1  \n",
       "2      17.8  392.83   4.03           1  \n",
       "3      18.7  394.63   2.94           1  \n",
       "4      18.7  396.90   5.33           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convergence warning: https://stackoverflow.com/questions/20681864/lasso-on-sklearn-does-not-converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dict = {}\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Specify the hyperparameter space\n",
    "parameters = {\n",
    "'model__alpha': np.linspace(0.2, 1, 5), \n",
    "'model__l1_ratio': np.linspace(0, 1, 5),\n",
    "'model__random_state':[42]\n",
    "}\n",
    "ml_model = ElasticNet()\n",
    "# set tol, default is 1e-4\n",
    "do_transform_label = 'log'\n",
    "c_space = np.logspace(-5, 1, 5)\n",
    "do_transform_label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test with different preprocessing steps\n",
    "There are 2 different X_sets: On X_train_onehot, I applied one-hot encoding, while on X_train I applied Ordinal Encoding. The former is aimed at linear regression models, and the later is generally used for tree models.\n",
    "\n",
    "On 'column' parameter, I am able to choose column groups. For instance, I might exclude collinear variables obtained from the VIF function applied on notebook 5. That is useful for linear regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "treat_collinearity = False, do_build_polynomals=False, do_treat_skewness=False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test type: False\n",
      "{'reg': {'best_params': {'model__alpha': 0.2,\n",
      "                         'model__l1_ratio': 0.75,\n",
      "                         'model__random_state': 42},\n",
      "         'best_score': 12.325632143994682,\n",
      "         'prediction_time': 0.0002005,\n",
      "         'train_time': 1.704025}}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'reg'\n",
    "ml_dict[model_type] = {}\n",
    "columns = X_train_onehot.columns\n",
    "\n",
    "clf, ml_dict[model_type]['train_time'], ml_dict[model_type]['prediction_time'] = apply_ml_model(\n",
    "    X_train_onehot, y_train, columns, ml_model, parameters, scoring,\n",
    "    do_build_polynomals=False, \n",
    "    do_treat_skewness=False,\n",
    "    imputation=Imputer(strategy='median'), scaler=StandardScaler(),\n",
    "    )\n",
    "ml_dict[model_type]['best_params'], ml_dict[model_type]['best_score']  = get_model_params(clf, scoring)\n",
    "pprint(ml_dict)\n",
    "\n",
    "save_model_parameters(models_reports, model_type, clf)\n",
    "save_model_metrics(model_outputs, model_type, ml_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "treat_collinearity = True, do_build_polynomals=False, do_treat_skewness=False,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test type: False\n",
      "{'reg': {'best_params': {'model__alpha': 0.2,\n",
      "                         'model__l1_ratio': 0.75,\n",
      "                         'model__random_state': 42},\n",
      "         'best_score': 12.325632143994682,\n",
      "         'prediction_time': 0.0002005,\n",
      "         'train_time': 1.704025},\n",
      " 'reg_nocol': {'best_params': {'model__alpha': 0.2,\n",
      "                               'model__l1_ratio': 0.75,\n",
      "                               'model__random_state': 42},\n",
      "               'best_score': 12.325632143994682,\n",
      "               'prediction_time': 0.0003001,\n",
      "               'train_time': 1.940997}}\n"
     ]
    }
   ],
   "source": [
    "model_type = 'reg_nocol'\n",
    "ml_dict[model_type] = {}\n",
    "\n",
    "# columns_nocol = dfs_dict['X_train_oh_nocol'].columns.to_list()\n",
    "\n",
    "clf, ml_dict[model_type]['train_time'], ml_dict[model_type]['prediction_time'] = apply_ml_model(\n",
    "    X_train_onehot, y_train, columns, ml_model, parameters, scoring,\n",
    "    do_build_polynomals=False, \n",
    "    do_treat_skewness=False,\n",
    "    imputation=Imputer(strategy='median'), scaler=StandardScaler(),\n",
    "    )\n",
    "ml_dict[model_type]['best_params'], ml_dict[model_type]['best_score']  = get_model_params(clf, scoring)\n",
    "pprint(ml_dict)\n",
    "\n",
    "save_model_parameters(models_reports, model_type, clf)\n",
    "save_model_metrics(model_outputs, model_type, ml_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I might use the alternative encoding just to demonstrate the impact on the score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
